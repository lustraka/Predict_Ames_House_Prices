{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z33tYpDfZiGz"
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import train_xgb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_RuEufmoaEQ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-154842\n",
      "aml-quickstarts-154842\n",
      "southcentralus\n",
      "9e65f93e-bdd8-437b-b1e8-0647cd6098f7\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S3i7e0x1aSAs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress.....\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded.......................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "# Create compute cluster\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           min_nodes=1,\n",
    "                                                           max_nodes=5)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jZYqKWd7bX4-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = (1460, 80), test.shape = (1459, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Method register_pandas_dataframe: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to managed-dataset/cc21130c-9bc5-4438-9ae2-0e0e62cd2eec/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "# Try to load the dataset from the workspace. Otherwise, load if from Kaggle\n",
    "found = False\n",
    "ds_key = 'Ames-housing-dataset'\n",
    "ds_desc = 'Ames Housing training data.'\n",
    "\n",
    "if ds_key in ws.datasets.keys():\n",
    "    found = True\n",
    "    dataset = ws.datasets[ds_key]\n",
    "    print(f'Found registered {ds_key}, use it.')\n",
    "    \n",
    "if not found:\n",
    "    train, test = train_xgb.load_data_clean(source='kaggle')\n",
    "    print(f\"train.shape = {train.shape}, test.shape = {test.shape}\")\n",
    "    # Register the train dataset\n",
    "    blob = ws.get_default_datastore()\n",
    "    dataset = TabularDatasetFactory.register_pandas_dataframe(train, blob, name=ds_key, description=ds_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoostRegressor Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r2gmKB_RaYx0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conda_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda_env.yml\n",
    "\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- pip:\n",
    "  - azureml-defaults==1.32.0\n",
    "- numpy>=1.16.0,<1.19.0\n",
    "- pandas==0.25.1\n",
    "- scikit-learn==0.22.1\n",
    "- py-xgboost<=0.90\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VeuPY0KkaiIJ"
   },
   "outputs": [],
   "source": [
    "with open('hdr-outputs/best_hdr_metrics.json', 'r') as file:\n",
    "    best_hdr_metrics = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6QrPxsvJaxw4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model Ames-Housing-XGB-Model\n",
      "Ames-Housing-XGB-Model\tAmes-Housing-XGB-Model:1\t1\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "# Register the best model\n",
    "model = Model.register(ws, model_path='hdr-outputs/model.pkl', model_name='Ames-Housing-XGB-Model', tags=best_hdr_metrics)\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fe34B7MXays1"
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                              memory_gb=1,\n",
    "                                              tags={\"data\" : \"Kaggle\", \"method\" : \"XGB\"},\n",
    "                                              description=\"Predict Ames Housing Prices\",\n",
    "                                              auth_enabled=True,\n",
    "                                              enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TbuGHr_Pa2mG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"project-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults==1.32.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"numpy>=1.16.0,<1.19.0\",\n",
       "                \"pandas==0.25.1\",\n",
       "                \"scikit-learn==0.22.1\",\n",
       "                \"py-xgboost<=0.90\"\n",
       "            ],\n",
       "            \"name\": \"azureml_0fb6b21ffdf9d1b5cda9af4e6196ec48\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = Environment(\"project-env\")\n",
    "cd = CondaDependencies('conda_env.yml')\n",
    "env.python.conda_dependencies = cd\n",
    "# Register environment to re-use later\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ILkvHXa9bBjY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-18 05:51:36+00:00 Creating Container Registry if not exists..\n",
      "2021-08-18 06:01:36+00:00 Registering the environment..\n",
      "2021-08-18 06:01:40+00:00 Building image..\n",
      "2021-08-18 06:08:41+00:00 Generating deployment configuration.\n",
      "2021-08-18 06:08:43+00:00 Submitting deployment to compute.\n",
      "2021-08-18 06:08:46+00:00 Checking the status of deployment ames-housing-xgb-a4df..\n",
      "2021-08-18 06:11:16+00:00 Checking the status of inference endpoint ames-housing-xgb-a4df.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 2.27 s, sys: 274 ms, total: 2.54 s\n",
      "Wall time: 19min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import uuid\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "model = Model(ws, 'Ames-Housing-XGB-Model')\n",
    "\n",
    "myenv = Environment.get(workspace=ws, name=\"project-env\", version=\"1\")\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"entry_script.py\", environment=myenv)\n",
    "\n",
    "service_name = 'ames-housing-xgb-' + str(uuid.uuid4())[:4]\n",
    "service = Model.deploy(workspace=ws,\n",
    "                      name=service_name,\n",
    "                      models=[model],\n",
    "                      inference_config=inference_config,\n",
    "                      deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y--m0e0IbCVH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-18T06:11:07,834845400+00:00 - gunicorn/run \n",
      "File not found: /var/azureml-app/.\n",
      "Starting HTTP server\n",
      "2021-08-18T06:11:07,834933400+00:00 - iot-server/run \n",
      "2021-08-18T06:11:07,836212000+00:00 - rsyslog/run \n",
      "2021-08-18T06:11:07,880292900+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-08-18T06:11:08,295533100+00:00 - iot-server/finish 1 0\n",
      "2021-08-18T06:11:08,297477700+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (59)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 87\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-08-18 06:11:09,920 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2021-08-18 06:11:09,921 | root | INFO | Starting up request id generator\n",
      "2021-08-18 06:11:09,921 | root | INFO | Starting up app insight hooks\n",
      "2021-08-18 06:11:09,921 | root | INFO | Invoking user's init function\n",
      "2021-08-18 06:11:10,663 | root | INFO | Users's init has completed successfully\n",
      "2021-08-18 06:11:10,666 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-08-18 06:11:10,666 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-08-18 06:11:10,670 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-08-18 06:11:16,387 | root | INFO | Swagger file not present\n",
      "2021-08-18 06:11:16,388 | root | INFO | 404\n",
      "127.0.0.1 - - [18/Aug/2021:06:11:16 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-18 06:11:21,426 | root | INFO | Swagger file not present\n",
      "2021-08-18 06:11:21,427 | root | INFO | 404\n",
      "127.0.0.1 - - [18/Aug/2021:06:11:21 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CQTCpmrkbLNE"
   },
   "outputs": [],
   "source": [
    "# Prepare data for request\n",
    "_ , test = train_xgb.load_data_clean()\n",
    "test = train_xgb.label_encode(test)\n",
    "data = {'data': test.head().to_dict(orient='list')}\n",
    "\n",
    "# Replace the next cell with the code from 'Consume' tab of the endpoint\n",
    "# and delete 'data = {}' assignment as data is defined in this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"{\\\\\"result\\\\\": [124214.375, 159119.453125, 175328.28125, 186762.34375, 190019.46875]}\"'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# data = {\n",
    "# }\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'http://39c4adc7-bbd5-4280-9cc5-b42fd7cf92c0.southcentralus.azurecontainer.io/score'\n",
    "api_key = 'YH89fnGQYMygbn0gQhZYxXzYB5dwxpuk' # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-18T06:11:07,834845400+00:00 - gunicorn/run \n",
      "File not found: /var/azureml-app/.\n",
      "Starting HTTP server\n",
      "2021-08-18T06:11:07,834933400+00:00 - iot-server/run \n",
      "2021-08-18T06:11:07,836212000+00:00 - rsyslog/run \n",
      "2021-08-18T06:11:07,880292900+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-08-18T06:11:08,295533100+00:00 - iot-server/finish 1 0\n",
      "2021-08-18T06:11:08,297477700+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (59)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 87\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-08-18 06:11:09,920 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2021-08-18 06:11:09,921 | root | INFO | Starting up request id generator\n",
      "2021-08-18 06:11:09,921 | root | INFO | Starting up app insight hooks\n",
      "2021-08-18 06:11:09,921 | root | INFO | Invoking user's init function\n",
      "2021-08-18 06:11:10,663 | root | INFO | Users's init has completed successfully\n",
      "2021-08-18 06:11:10,666 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-08-18 06:11:10,666 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-08-18 06:11:10,670 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-08-18 06:11:16,387 | root | INFO | Swagger file not present\n",
      "2021-08-18 06:11:16,388 | root | INFO | 404\n",
      "127.0.0.1 - - [18/Aug/2021:06:11:16 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-18 06:11:21,426 | root | INFO | Swagger file not present\n",
      "2021-08-18 06:11:21,427 | root | INFO | 404\n",
      "127.0.0.1 - - [18/Aug/2021:06:11:21 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-18 06:13:04,917 | root | INFO | Swagger file not present\n",
      "2021-08-18 06:13:04,918 | root | INFO | 404\n",
      "127.0.0.1 - - [18/Aug/2021:06:13:04 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-18 06:13:40,564 | root | INFO | Validation Request Content-Type\n",
      "2021-08-18 06:13:40,568 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "data.shape = (5, 79)\n",
      "dd09d013-bca0-4011-9cfc-e0499999a5f0,data.shape = (5, 79)\n",
      "\n",
      "2021-08-18 06:13:40,611 | root | INFO | 200\n",
      "127.0.0.1 - - [18/Aug/2021:06:13:40 +0000] \"POST /score HTTP/1.0\" 200 85 \"-\" \"Python-urllib/3.6\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())\n",
    "# Clean up resources\n",
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aml-outputs/best_aml_metrics.json', 'r') as file:\n",
    "    best_aml_metrics = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model Ames-Housing-AutoML-Model\n",
      "Ames-Housing-AutoML-Model\tAmes-Housing-AutoML-Model:1\t1\n"
     ]
    }
   ],
   "source": [
    "# Register the best model\n",
    "model = Model.register(ws, model_path='aml-outputs/model.pkl', model_name='Ames-Housing-AutoML-Model', tags=best_aml_metrics)\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                              memory_gb=1,\n",
    "                                              tags={\"data\" : \"Kaggle\", \"method\" : \"AutoML\"},\n",
    "                                              description=\"Predict Ames Housing Prices\",\n",
    "                                              auth_enabled=True,\n",
    "                                              enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": true,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"project-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-train-automl-runtime==1.33.0\",\n",
       "                        \"inference-schema\",\n",
       "                        \"azureml-interpret==1.33.0\",\n",
       "                        \"azureml-defaults==1.33.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"numpy>=1.16.0,<1.19.0\",\n",
       "                \"pandas==0.25.1\",\n",
       "                \"scikit-learn==0.22.1\",\n",
       "                \"py-xgboost<=0.90\",\n",
       "                \"fbprophet==0.5\",\n",
       "                \"holidays==0.9.11\",\n",
       "                \"psutil>=5.2.2,<6.0.0\"\n",
       "            ],\n",
       "            \"name\": \"azureml_59fba923920e15fa8fbe872c700ad33f\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"6\"\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = Environment(\"project-env\")\n",
    "cd = CondaDependencies('aml-outputs/conda_env_v_1_0_0.yml')\n",
    "env.python.conda_dependencies = cd\n",
    "# Creates the environment inside a Docker container.\n",
    "env.docker.enabled = True\n",
    "# Register environment to re-use later\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-18 06:27:05+00:00 Registering the environment.\n",
      "2021-08-18 06:27:09+00:00 Building image..\n",
      "2021-08-18 06:42:40+00:00 Generating deployment configuration.\n",
      "2021-08-18 06:42:42+00:00 Submitting deployment to compute..\n",
      "2021-08-18 06:42:44+00:00 Checking the status of deployment ames-housing-aml-19ca..\n",
      "2021-08-18 06:47:22+00:00 Checking the status of inference endpoint ames-housing-aml-19ca.\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
      "Operation ID: 88639e42-a95c-4e5a-8bdb-167af573b030\n",
      "More information can be found using '.get_logs()'\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"AciDeploymentFailed\",\n",
      "  \"statusCode\": 400,\n",
      "  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
      "\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
      "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
      "\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n",
      "  \"details\": [\n",
      "    {\n",
      "      \"code\": \"CrashLoopBackOff\",\n",
      "      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
      "\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
      "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
      "\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"AciDeploymentFailed\",\n",
      "      \"message\": \"Your container application crashed. Please follow the steps to debug:\n",
      "\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n",
      "\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n",
      "\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
      "\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n",
      "\"RestartCount\": 3\n",
      "\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n",
      "\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-08-18T06:48:40.307Z\",\"exitCode\":111,\"finishTime\":\"2021-08-18T06:48:47.612Z\",\"detailStatus\":\"Error\"}\n",
      "\"Events\":\n",
      "{\"count\":2,\"firstTimestamp\":\"2021-08-18T06:42:51Z\",\"lastTimestamp\":\"2021-08-18T06:46:51Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\"\",\"type\":\"Normal\"}\n",
      "{\"count\":2,\"firstTimestamp\":\"2021-08-18T06:46:50Z\",\"lastTimestamp\":\"2021-08-18T06:46:51Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\"\",\"type\":\"Normal\"}\n",
      "{\"count\":4,\"firstTimestamp\":\"2021-08-18T06:47:14Z\",\"lastTimestamp\":\"2021-08-18T06:48:40Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n",
      "{\"count\":4,\"firstTimestamp\":\"2021-08-18T06:47:20Z\",\"lastTimestamp\":\"2021-08-18T06:48:47Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 5d0d05398e686545285d64ba5b876b440f620a3d292a09d87e8b1f0fe8097a88.\",\"type\":\"Normal\"}\n",
      "\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 88639e42-a95c-4e5a-8bdb-167af573b030\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-08-18T06:48:40.307Z\",\"exitCode\":111,\"finishTime\":\"2021-08-18T06:48:47.612Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":2,\"firstTimestamp\":\"2021-08-18T06:42:51Z\",\"lastTimestamp\":\"2021-08-18T06:46:51Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\"\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2021-08-18T06:46:50Z\",\"lastTimestamp\":\"2021-08-18T06:46:51Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\"\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-08-18T06:47:14Z\",\"lastTimestamp\":\"2021-08-18T06:48:40Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-08-18T06:47:20Z\",\"lastTimestamp\":\"2021-08-18T06:48:47Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 5d0d05398e686545285d64ba5b876b440f620a3d292a09d87e8b1f0fe8097a88.\",\"type\":\"Normal\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 88639e42-a95c-4e5a-8bdb-167af573b030\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-08-18T06:48:40.307Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-08-18T06:48:47.612Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-08-18T06:42:51Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-18T06:46:51Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-08-18T06:46:50Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-18T06:46:51Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-08-18T06:47:14Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-18T06:48:40Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-08-18T06:47:20Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-18T06:48:47Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id 5d0d05398e686545285d64ba5b876b440f620a3d292a09d87e8b1f0fe8097a88.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    923\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 925\u001b[0;31m                                                       logs_response, format_error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    926\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    927\u001b[0m                                                                                   operation_state))\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 88639e42-a95c-4e5a-8bdb-167af573b030\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-08-18T06:48:40.307Z\",\"exitCode\":111,\"finishTime\":\"2021-08-18T06:48:47.612Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":2,\"firstTimestamp\":\"2021-08-18T06:42:51Z\",\"lastTimestamp\":\"2021-08-18T06:46:51Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\"\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2021-08-18T06:46:50Z\",\"lastTimestamp\":\"2021-08-18T06:46:51Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\"\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-08-18T06:47:14Z\",\"lastTimestamp\":\"2021-08-18T06:48:40Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-08-18T06:47:20Z\",\"lastTimestamp\":\"2021-08-18T06:48:47Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 5d0d05398e686545285d64ba5b876b440f620a3d292a09d87e8b1f0fe8097a88.\",\"type\":\"Normal\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 88639e42-a95c-4e5a-8bdb-167af573b030\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: ames-housing-aml-19ca. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-08-18T06:48:40.307Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-08-18T06:48:47.612Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-08-18T06:42:51Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-18T06:46:51Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-08-18T06:46:50Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-18T06:46:51Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"4ef97ab113bd43d4ba448835c4fb75db.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f06e83da6b291cafd493141da1b85a5b2a450cea152e034cbbf4f799a87fecb1\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-08-18T06:47:14Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-18T06:48:40Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-08-18T06:47:20Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-18T06:48:47Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id 5d0d05398e686545285d64ba5b876b440f620a3d292a09d87e8b1f0fe8097a88.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import uuid\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "model = Model(ws, 'Ames-Housing-AutoML-Model')\n",
    "\n",
    "myenv = Environment.get(workspace=ws, name=\"project-env\")\n",
    "inference_config = InferenceConfig(entry_script=\"aml-outputs/scoring_file_v_1_0_0.py\", environment=myenv)\n",
    "\n",
    "service_name = 'ames-housing-aml-' + str(uuid.uuid4())[:4]\n",
    "service = Model.deploy(workspace=ws,\n",
    "                      name=service_name,\n",
    "                      models=[model],\n",
    "                      inference_config=inference_config,\n",
    "                      deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ws.webservices['ames-housing-aml-19ca'].get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for request\n",
    "_ , test = train_xgb.load_data_clean()\n",
    "data = {'data': test.head().to_dict(orient='list')}\n",
    "\n",
    "# Replace the next cell with the code from 'Consume' tab of the endpoint\n",
    "# and delete 'data = {}' assignment as data is defined in this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "5UNkEY6kbRdX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())\n",
    "# Clean up resources\n",
    "service.delete()\n",
    "cpu_cluster.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOSX0MhajOBifJeXHjxYDTH",
   "name": "Deployment-testing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
