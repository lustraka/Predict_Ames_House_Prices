{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z33tYpDfZiGz"
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import train_xgb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_RuEufmoaEQ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-154990\n",
      "aml-quickstarts-154990\n",
      "southcentralus\n",
      "610d6e37-4747-4a20-80eb-3aad70a55f43\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S3i7e0x1aSAs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress......\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded......................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "# Create compute cluster\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           min_nodes=1,\n",
    "                                                           max_nodes=5)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jZYqKWd7bX4-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = (1460, 80), test.shape = (1459, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Method register_pandas_dataframe: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to managed-dataset/c0e9801f-3f05-4219-9718-9b8b650ee129/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "# Try to load the dataset from the workspace. Otherwise, load if from Kaggle\n",
    "found = False\n",
    "ds_key = 'Ames-housing-dataset'\n",
    "ds_desc = 'Ames Housing training data.'\n",
    "\n",
    "if ds_key in ws.datasets.keys():\n",
    "    found = True\n",
    "    dataset = ws.datasets[ds_key]\n",
    "    print(f'Found registered {ds_key}, use it.')\n",
    "    \n",
    "if not found:\n",
    "    train, test = train_xgb.load_data_clean(source='kaggle')\n",
    "    print(f\"train.shape = {train.shape}, test.shape = {test.shape}\")\n",
    "    # Register the train dataset\n",
    "    blob = ws.get_default_datastore()\n",
    "    dataset = TabularDatasetFactory.register_pandas_dataframe(train, blob, name=ds_key, description=ds_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoostRegressor Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r2gmKB_RaYx0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conda_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda_env.yml\n",
    "\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- pip:\n",
    "  - azureml-defaults==1.32.0\n",
    "- numpy>=1.16.0,<1.19.0\n",
    "- pandas==0.25.1\n",
    "- scikit-learn==0.22.1\n",
    "- py-xgboost<=0.90\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VeuPY0KkaiIJ"
   },
   "outputs": [],
   "source": [
    "with open('hdr-outputs/best_hdr_metrics.json', 'r') as file:\n",
    "    best_hdr_metrics = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6QrPxsvJaxw4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model Ames-Housing-XGB-Model\n",
      "Ames-Housing-XGB-Model\tAmes-Housing-XGB-Model:1\t1\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "# Register the best model\n",
    "model = Model.register(ws, model_path='hdr-outputs/model.pkl', model_name='Ames-Housing-XGB-Model', tags=best_hdr_metrics)\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fe34B7MXays1"
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                              memory_gb=1,\n",
    "                                              tags={\"data\" : \"Kaggle\", \"method\" : \"XGB\"},\n",
    "                                              description=\"Predict Ames Housing Prices\",\n",
    "                                              auth_enabled=True,\n",
    "                                              enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TbuGHr_Pa2mG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"project-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults==1.32.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"numpy>=1.16.0,<1.19.0\",\n",
       "                \"pandas==0.25.1\",\n",
       "                \"scikit-learn==0.22.1\",\n",
       "                \"py-xgboost<=0.90\"\n",
       "            ],\n",
       "            \"name\": \"azureml_0fb6b21ffdf9d1b5cda9af4e6196ec48\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = Environment(\"project-env\")\n",
    "cd = CondaDependencies('conda_env.yml')\n",
    "env.python.conda_dependencies = cd\n",
    "# Register environment to re-use later\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ILkvHXa9bBjY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-19 05:38:48+00:00 Creating Container Registry if not exists..\n",
      "2021-08-19 05:48:48+00:00 Registering the environment..\n",
      "2021-08-19 05:48:51+00:00 Building image..\n",
      "2021-08-19 05:55:52+00:00 Generating deployment configuration..\n",
      "2021-08-19 05:55:53+00:00 Submitting deployment to compute.\n",
      "2021-08-19 05:55:56+00:00 Checking the status of deployment ames-housing-xgb-4006..\n",
      "2021-08-19 05:58:40+00:00 Checking the status of inference endpoint ames-housing-xgb-4006.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 2.55 s, sys: 295 ms, total: 2.85 s\n",
      "Wall time: 19min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import uuid\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "model = Model(ws, 'Ames-Housing-XGB-Model')\n",
    "\n",
    "myenv = Environment.get(workspace=ws, name=\"project-env\")\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"entry_script.py\", environment=myenv)\n",
    "\n",
    "service_name = 'ames-housing-xgb-' + str(uuid.uuid4())[:4]\n",
    "service = Model.deploy(workspace=ws,\n",
    "                      name=service_name,\n",
    "                      models=[model],\n",
    "                      inference_config=inference_config,\n",
    "                      deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y--m0e0IbCVH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-19T05:58:30,138589800+00:00 - rsyslog/run \n",
      "2021-08-19T05:58:30,140069900+00:00 - gunicorn/run \n",
      "File not found: /var/azureml-app/.\n",
      "Starting HTTP server\n",
      "2021-08-19T05:58:30,164580700+00:00 - iot-server/run \n",
      "2021-08-19T05:58:30,186601400+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-08-19T05:58:30,508799700+00:00 - iot-server/finish 1 0\n",
      "2021-08-19T05:58:30,511827400+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (61)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 89\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-08-19 05:58:32,105 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2021-08-19 05:58:32,110 | root | INFO | Starting up request id generator\n",
      "2021-08-19 05:58:32,110 | root | INFO | Starting up app insight hooks\n",
      "2021-08-19 05:58:32,110 | root | INFO | Invoking user's init function\n",
      "2021-08-19 05:58:32,926 | root | INFO | Users's init has completed successfully\n",
      "2021-08-19 05:58:32,933 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-08-19 05:58:32,933 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-08-19 05:58:32,935 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-08-19 05:58:40,819 | root | INFO | Swagger file not present\n",
      "2021-08-19 05:58:40,819 | root | INFO | 404\n",
      "127.0.0.1 - - [19/Aug/2021:05:58:40 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-19 05:58:43,177 | root | INFO | Swagger file not present\n",
      "2021-08-19 05:58:43,178 | root | INFO | 404\n",
      "127.0.0.1 - - [19/Aug/2021:05:58:43 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CQTCpmrkbLNE"
   },
   "outputs": [],
   "source": [
    "# Prepare data for request\n",
    "_ , test = train_xgb.load_data_clean()\n",
    "test = train_xgb.label_encode(test)\n",
    "data = {'data': test.head().to_dict(orient='list')}\n",
    "\n",
    "# Replace the next cell with the code from 'Consume' tab of the endpoint\n",
    "# and delete 'data = {}' assignment as data is defined in this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"{\\\\\"result\\\\\": [124214.375, 159119.453125, 175328.28125, 186762.34375, 190019.46875]}\"'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# data = {\n",
    "# }\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'http://1e0b5126-672b-4e49-8aa7-7ae581c2aa03.southcentralus.azurecontainer.io/score'\n",
    "api_key = 'Vvo2X6KqfTk8WdCmam8rscslkmY5NsCd' # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-19T05:58:30,138589800+00:00 - rsyslog/run \n",
      "2021-08-19T05:58:30,140069900+00:00 - gunicorn/run \n",
      "File not found: /var/azureml-app/.\n",
      "Starting HTTP server\n",
      "2021-08-19T05:58:30,164580700+00:00 - iot-server/run \n",
      "2021-08-19T05:58:30,186601400+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-08-19T05:58:30,508799700+00:00 - iot-server/finish 1 0\n",
      "2021-08-19T05:58:30,511827400+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (61)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 89\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-08-19 05:58:32,105 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2021-08-19 05:58:32,110 | root | INFO | Starting up request id generator\n",
      "2021-08-19 05:58:32,110 | root | INFO | Starting up app insight hooks\n",
      "2021-08-19 05:58:32,110 | root | INFO | Invoking user's init function\n",
      "2021-08-19 05:58:32,926 | root | INFO | Users's init has completed successfully\n",
      "2021-08-19 05:58:32,933 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-08-19 05:58:32,933 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-08-19 05:58:32,935 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-08-19 05:58:40,819 | root | INFO | Swagger file not present\n",
      "2021-08-19 05:58:40,819 | root | INFO | 404\n",
      "127.0.0.1 - - [19/Aug/2021:05:58:40 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-19 05:58:43,177 | root | INFO | Swagger file not present\n",
      "2021-08-19 05:58:43,178 | root | INFO | 404\n",
      "127.0.0.1 - - [19/Aug/2021:05:58:43 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-19 06:01:27,155 | root | INFO | Swagger file not present\n",
      "2021-08-19 06:01:27,155 | root | INFO | 404\n",
      "127.0.0.1 - - [19/Aug/2021:06:01:27 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-19 06:01:59,462 | root | INFO | Validation Request Content-Type\n",
      "2021-08-19 06:01:59,464 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "data.shape = (5, 79)\n",
      "720a2624-f5d8-41a1-b062-79bfa2ebc7e4,data.shape = (5, 79)\n",
      "\n",
      "2021-08-19 06:01:59,541 | root | INFO | 200\n",
      "127.0.0.1 - - [19/Aug/2021:06:01:59 +0000] \"POST /score HTTP/1.0\" 200 85 \"-\" \"Python-urllib/3.6\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())\n",
    "# Clean up resources\n",
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aml-outputs/best_aml_metrics.json', 'r') as file:\n",
    "    best_aml_metrics = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model Ames-Housing-AutoML-Model\n",
      "Ames-Housing-AutoML-Model\tAmes-Housing-AutoML-Model:1\t1\n"
     ]
    }
   ],
   "source": [
    "# Register the best model\n",
    "model = Model.register(ws, model_path='aml-outputs/model.pkl', model_name='Ames-Housing-AutoML-Model', tags=best_aml_metrics)\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                              memory_gb=1,\n",
    "                                              tags={\"data\" : \"Kaggle\", \"method\" : \"AutoML\"},\n",
    "                                              description=\"Predict Ames Housing Prices\",\n",
    "                                              auth_enabled=True,\n",
    "                                              enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"project-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-train-automl-runtime==1.33.0\",\n",
       "                        \"inference-schema\",\n",
       "                        \"azureml-interpret==1.33.0\",\n",
       "                        \"azureml-defaults==1.33.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"numpy>=1.16.0,<1.19.0\",\n",
       "                \"pandas==0.25.1\",\n",
       "                \"scikit-learn==0.22.1\",\n",
       "                \"py-xgboost<=0.90\",\n",
       "                \"fbprophet==0.5\",\n",
       "                \"holidays==0.9.11\",\n",
       "                \"psutil>=5.2.2,<6.0.0\"\n",
       "            ],\n",
       "            \"name\": \"azureml_59fba923920e15fa8fbe872c700ad33f\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"3\"\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = Environment(\"project-env\")\n",
    "cd = CondaDependencies('aml-outputs/conda_env_v_1_0_0.yml')\n",
    "env.python.conda_dependencies = cd\n",
    "# Creates the environment inside a Docker container.\n",
    "# env.docker.enabled = True\n",
    "# Register environment to re-use later\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-19 06:03:11+00:00 Creating Container Registry if not exists.\n",
      "2021-08-19 06:03:11+00:00 Registering the environment.\n",
      "2021-08-19 06:03:13+00:00 Building image..\n",
      "2021-08-19 06:18:48+00:00 Generating deployment configuration..\n",
      "2021-08-19 06:18:49+00:00 Submitting deployment to compute.\n",
      "2021-08-19 06:18:52+00:00 Checking the status of deployment ames-housing-aml-0812..\n",
      "2021-08-19 06:22:48+00:00 Checking the status of inference endpoint ames-housing-aml-0812.\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
      "Operation ID: e29418d6-3866-4603-91f8-0b2cb756ebc1\n",
      "More information can be found using '.get_logs()'\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"AciDeploymentFailed\",\n",
      "  \"statusCode\": 400,\n",
      "  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
      "\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
      "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
      "\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n",
      "  \"details\": [\n",
      "    {\n",
      "      \"code\": \"CrashLoopBackOff\",\n",
      "      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n",
      "\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n",
      "\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
      "\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"AciDeploymentFailed\",\n",
      "      \"message\": \"Your container application crashed. Please follow the steps to debug:\n",
      "\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n",
      "\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n",
      "\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n",
      "\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n",
      "\"RestartCount\": 3\n",
      "\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n",
      "\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-08-19T06:24:07.256Z\",\"exitCode\":111,\"finishTime\":\"2021-08-19T06:24:13.387Z\",\"detailStatus\":\"Error\"}\n",
      "\"Events\":\n",
      "{\"count\":2,\"firstTimestamp\":\"2021-08-19T06:18:58Z\",\"lastTimestamp\":\"2021-08-19T06:22:20Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\"\",\"type\":\"Normal\"}\n",
      "{\"count\":2,\"firstTimestamp\":\"2021-08-19T06:22:20Z\",\"lastTimestamp\":\"2021-08-19T06:22:20Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\"\",\"type\":\"Normal\"}\n",
      "{\"count\":4,\"firstTimestamp\":\"2021-08-19T06:22:34Z\",\"lastTimestamp\":\"2021-08-19T06:24:07Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n",
      "{\"count\":4,\"firstTimestamp\":\"2021-08-19T06:22:39Z\",\"lastTimestamp\":\"2021-08-19T06:24:13Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 66ba6b84d7282b5366c98e93782b19716a0da22f87ecf844a4f813ffe9753c32.\",\"type\":\"Normal\"}\n",
      "\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: e29418d6-3866-4603-91f8-0b2cb756ebc1\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-08-19T06:24:07.256Z\",\"exitCode\":111,\"finishTime\":\"2021-08-19T06:24:13.387Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":2,\"firstTimestamp\":\"2021-08-19T06:18:58Z\",\"lastTimestamp\":\"2021-08-19T06:22:20Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\"\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2021-08-19T06:22:20Z\",\"lastTimestamp\":\"2021-08-19T06:22:20Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\"\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-08-19T06:22:34Z\",\"lastTimestamp\":\"2021-08-19T06:24:07Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-08-19T06:22:39Z\",\"lastTimestamp\":\"2021-08-19T06:24:13Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 66ba6b84d7282b5366c98e93782b19716a0da22f87ecf844a4f813ffe9753c32.\",\"type\":\"Normal\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: e29418d6-3866-4603-91f8-0b2cb756ebc1\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-08-19T06:24:07.256Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-08-19T06:24:13.387Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-08-19T06:18:58Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-19T06:22:20Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-08-19T06:22:20Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-19T06:22:20Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-08-19T06:22:34Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-19T06:24:07Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-08-19T06:22:39Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-19T06:24:13Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id 66ba6b84d7282b5366c98e93782b19716a0da22f87ecf844a4f813ffe9753c32.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    923\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 925\u001b[0;31m                                                       logs_response, format_error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    926\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    927\u001b[0m                                                                                   operation_state))\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: e29418d6-3866-4603-91f8-0b2cb756ebc1\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2021-08-19T06:24:07.256Z\",\"exitCode\":111,\"finishTime\":\"2021-08-19T06:24:13.387Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":2,\"firstTimestamp\":\"2021-08-19T06:18:58Z\",\"lastTimestamp\":\"2021-08-19T06:22:20Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\"\",\"type\":\"Normal\"}\n{\"count\":2,\"firstTimestamp\":\"2021-08-19T06:22:20Z\",\"lastTimestamp\":\"2021-08-19T06:22:20Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\"\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-08-19T06:22:34Z\",\"lastTimestamp\":\"2021-08-19T06:24:07Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2021-08-19T06:22:39Z\",\"lastTimestamp\":\"2021-08-19T06:24:13Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 66ba6b84d7282b5366c98e93782b19716a0da22f87ecf844a4f813ffe9753c32.\",\"type\":\"Normal\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: e29418d6-3866-4603-91f8-0b2cb756ebc1\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: ames-housing-aml-0812. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-08-19T06:24:07.256Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-08-19T06:24:13.387Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-08-19T06:18:58Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-19T06:22:20Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":2,\\\"firstTimestamp\\\":\\\"2021-08-19T06:22:20Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-19T06:22:20Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"c726cd197c8d4e64902174bc769dc498.azurecr.io/azureml/azureml_e434aed78f9426216c7e0e89c0851446@sha256:f108f3922cd028c69f1560739e46003bcf3560a181056de8621ed8ec237a3057\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-08-19T06:22:34Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-19T06:24:07Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-08-19T06:22:39Z\\\",\\\"lastTimestamp\\\":\\\"2021-08-19T06:24:13Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id 66ba6b84d7282b5366c98e93782b19716a0da22f87ecf844a4f813ffe9753c32.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import uuid\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "model = Model(ws, 'Ames-Housing-AutoML-Model')\n",
    "\n",
    "myenv = Environment.get(workspace=ws, name=\"project-env\")\n",
    "inference_config = InferenceConfig(entry_script=\"aml-outputs/scoring_file_v_1_0_0.py\", environment=myenv)\n",
    "\n",
    "service_name = 'ames-housing-aml-' + str(uuid.uuid4())[:4]\n",
    "service = Model.deploy(workspace=ws,\n",
    "                      name=service_name,\n",
    "                      models=[model],\n",
    "                      inference_config=inference_config,\n",
    "                      deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ws.webservices['ames-housing-aml-0812'].get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for request\n",
    "_ , test = train_xgb.load_data_clean()\n",
    "data = {'data': test.head().to_dict(orient='list')}\n",
    "\n",
    "# Replace the next cell with the code from 'Consume' tab of the endpoint\n",
    "# and delete 'data = {}' assignment as data is defined in this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5UNkEY6kbRdX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-19T06:26:27,601881200+00:00 - gunicorn/run \n",
      "File not found: /var/azureml-app/.\n",
      "Starting HTTP server\n",
      "2021-08-19T06:26:27,606814100+00:00 - rsyslog/run \n",
      "2021-08-19T06:26:27,614454100+00:00 - iot-server/run \n",
      "2021-08-19T06:26:27,700982400+00:00 - nginx/run \n",
      "rsyslogd: /azureml-envs/azureml_59fba923920e15fa8fbe872c700ad33f/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-08-19T06:26:28,065364700+00:00 - iot-server/finish 1 0\n",
      "2021-08-19T06:26:28,071959800+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (544)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 572\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Generating new fontManager, this may take some time...\n",
      "Exception in worker process\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/routes_common.py\", line 37, in <module>\n",
      "    from azureml.api.exceptions.ClientSideException import ClientSideException\n",
      "ModuleNotFoundError: No module named 'azureml.api'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_59fba923920e15fa8fbe872c700ad33f/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 589, in spawn_worker\n",
      "    worker.init_process()\n",
      "  File \"/azureml-envs/azureml_59fba923920e15fa8fbe872c700ad33f/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 134, in init_process\n",
      "    self.load_wsgi()\n",
      "  File \"/azureml-envs/azureml_59fba923920e15fa8fbe872c700ad33f/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 146, in load_wsgi\n",
      "    self.wsgi = self.app.wsgi()\n",
      "  File \"/azureml-envs/azureml_59fba923920e15fa8fbe872c700ad33f/lib/python3.6/site-packages/gunicorn/app/base.py\", line 67, in wsgi\n",
      "    self.callable = self.load()\n",
      "  File \"/azureml-envs/azureml_59fba923920e15fa8fbe872c700ad33f/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 58, in load\n",
      "    return self.load_wsgiapp()\n",
      "  File \"/azureml-envs/azureml_59fba923920e15fa8fbe872c700ad33f/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 48, in load_wsgiapp\n",
      "    return util.import_app(self.app_uri)\n",
      "  File \"/azureml-envs/azureml_59fba923920e15fa8fbe872c700ad33f/lib/python3.6/site-packages/gunicorn/util.py\", line 359, in import_app\n",
      "    mod = importlib.import_module(module)\n",
      "  File \"/azureml-envs/azureml_59fba923920e15fa8fbe872c700ad33f/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n",
      "  File \"/var/azureml-server/entry.py\", line 1, in <module>\n",
      "    import create_app\n",
      "  File \"/var/azureml-server/create_app.py\", line 4, in <module>\n",
      "    from routes_common import main\n",
      "  File \"/var/azureml-server/routes_common.py\", line 39, in <module>\n",
      "    from azure.ml.api.exceptions.ClientSideException import ClientSideException\n",
      "ModuleNotFoundError: No module named 'azure.ml'\n",
      "Worker exiting (pid: 572)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2021-08-19T06:26:31,522542800+00:00 - gunicorn/finish 3 0\n",
      "2021-08-19T06:26:31,523909200+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())\n",
    "# Clean up resources\n",
    "service.delete()\n",
    "cpu_cluster.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOSX0MhajOBifJeXHjxYDTH",
   "name": "Deployment-testing.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
