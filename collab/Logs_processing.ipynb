{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7oIZCZa7R1bqyvFWiuo5Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lustraka/Predict_Ames_House_Prices/blob/main/collab/Logs_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzlsUVgqQ1O6"
      },
      "source": [
        "# Import dependencies\n",
        "import requests\n",
        "import ast\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrqj5GBvQ5sT"
      },
      "source": [
        "urls = {\n",
        "    \"Metrics\" : 'https://raw.githubusercontent.com/lustraka/Predict_Ames_House_Prices/main/logs/session0723/best_run_metrics.json',\n",
        "    \"Details\" : 'https://raw.githubusercontent.com/lustraka/Predict_Ames_House_Prices/main/logs/session0723/best_run_details.txt',\n",
        "    \"Model\" : 'https://github.com/lustraka/Predict_Ames_House_Prices/blob/main/logs/session0723/AutoMLcd63750fd36.zip?raw=true'\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4IMoZ3_-SsOx",
        "outputId": "ab144962-f827-467e-973c-65e96b01872f"
      },
      "source": [
        "# Model details\n",
        "details = requests.get(urls['Details']).text\n",
        "details = ast.literal_eval(details)\n",
        "# A pattern for extracting structure of the VotingEnsemble model\n",
        "voting_ensemble = {k:ast.literal_eval(details['properties'][k]) for k in ['ensembled_algorithms', 'ensemble_weights']}\n",
        "pd.DataFrame(voting_ensemble).sort_values(by='ensemble_weights', ascending=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ensembled_algorithms</th>\n",
              "      <th>ensemble_weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBoostRegressor</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoostRegressor</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ElasticNet</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SGD</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ensembled_algorithms  ensemble_weights\n",
              "0     XGBoostRegressor          0.400000\n",
              "2     XGBoostRegressor          0.266667\n",
              "1             LightGBM          0.133333\n",
              "4           ElasticNet          0.133333\n",
              "3                  SGD          0.066667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POwSAbSRT46q",
        "outputId": "e7fac066-2c50-4a49-8f7f-c9f25ece1427"
      },
      "source": [
        "# Model metrics\n",
        "metrics = requests.get(urls['Metrics'])\n",
        "metrics.json()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'explained_variance': 0.886052769069071,\n",
              " 'mean_absolute_error': 15439.116472115917,\n",
              " 'mean_absolute_percentage_error': 9.122770171936464,\n",
              " 'median_absolute_error': 9654.516791774067,\n",
              " 'normalized_mean_absolute_error': 0.021440239511339974,\n",
              " 'normalized_median_absolute_error': 0.013407188990104244,\n",
              " 'normalized_root_mean_squared_error': 0.037139291460024836,\n",
              " 'normalized_root_mean_squared_log_error': 0.042947817229549566,\n",
              " 'predicted_true': 'aml://artifactId/ExperimentRun/dcid.AutoML_cd63750f-df45-4803-b135-af0f23de09cd_36/predicted_true',\n",
              " 'r2_score': 0.885898472424608,\n",
              " 'residuals': 'aml://artifactId/ExperimentRun/dcid.AutoML_cd63750f-df45-4803-b135-af0f23de09cd_36/residuals',\n",
              " 'root_mean_squared_error': 26744.00378036388,\n",
              " 'root_mean_squared_log_error': 0.13203033398097183,\n",
              " 'spearman_correlation': 0.9573852130501542}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtPD9eOgUt1o"
      },
      "source": [
        "# Working With a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3QsxM7PcxFl"
      },
      "source": [
        "import zipfile\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMJ5TrZBUevx"
      },
      "source": [
        "model = requests.get(urls['Model'])\n",
        "with open('model.zip', 'bw') as archive:\n",
        "  archive.write(model.content)\n",
        "with zipfile.ZipFile('model.zip', 'r') as file:\n",
        "  file.extractall()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-9kgdnQY_Wh",
        "outputId": "261c991d-a089-446a-8e41-4c5dd7b4813b"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'model.zip',\n",
              " 'model.pkl',\n",
              " 'conda_env_v_1_0_0.yml',\n",
              " 'scoring_file_v_1_0_0.py',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4IXNgZXbb8m",
        "outputId": "2a2752bd-6c6e-4386-9a9f-b0dff6dc0877"
      },
      "source": [
        "! pip install --upgrade azureml-sdk[notebooks,automl]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: azureml-sdk[automl,notebooks] in /usr/local/lib/python3.7/dist-packages (1.32.0)\n",
            "Requirement already satisfied: azureml-train-automl-client~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-train~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-pipeline~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-dataset-runtime[fuse]~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-core~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-contrib-notebook~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-widgets~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-train-automl~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: nbconvert<6 in /usr/local/lib/python3.7/dist-packages (from azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (5.6.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (4.10.1)\n",
            "Requirement already satisfied: azureml-pipeline-core~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: papermill<2 in /usr/local/lib/python3.7/dist-packages (from azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (1.2.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (5.5.0)\n",
            "Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.1.27)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (2018.9)\n",
            "Requirement already satisfied: azure-mgmt-keyvault<10.0.0,>=0.40.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (9.0.0)\n",
            "Requirement already satisfied: pathspec<1.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.9.0)\n",
            "Requirement already satisfied: contextlib2<1.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.5.5)\n",
            "Requirement already satisfied: SecretStorage<4.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (3.3.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.19.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (2.23.0)\n",
            "Requirement already satisfied: azure-mgmt-storage<16.0.0,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (11.2.0)\n",
            "Requirement already satisfied: urllib3<=1.26.5,>=1.23 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.24.3)\n",
            "Requirement already satisfied: msrest<1.0.0,>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.6.21)\n",
            "Requirement already satisfied: ruamel.yaml<0.17.5,>=0.15.35 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.17.4)\n",
            "Requirement already satisfied: azure-mgmt-containerregistry>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (8.1.0)\n",
            "Requirement already satisfied: pyopenssl<21.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (20.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (2.8.1)\n",
            "Requirement already satisfied: azure-mgmt-resource<15.0.0,>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (13.0.0)\n",
            "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.61.1)\n",
            "Requirement already satisfied: adal<=1.2.7,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.2.7)\n",
            "Requirement already satisfied: jsonpickle<3.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (2.0.0)\n",
            "Requirement already satisfied: docker<5.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (4.4.4)\n",
            "Requirement already satisfied: ndg-httpsclient<=0.5.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.5.1)\n",
            "Requirement already satisfied: azure-mgmt-authorization<1.0.0,>=0.40.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.61.0)\n",
            "Requirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (3.4.7)\n",
            "Requirement already satisfied: msrestazure<=0.6.4,>=0.4.33 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.6.4)\n",
            "Requirement already satisfied: jmespath<1.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.10.0)\n",
            "Requirement already satisfied: PyJWT<3.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (2.1.0)\n",
            "Requirement already satisfied: backports.tempfile in /usr/local/lib/python3.7/dist-packages (from azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.0)\n",
            "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from azure-mgmt-containerregistry>=2.0.0->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.3.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-containerregistry>=2.0.0->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.16.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from azure-core<2.0.0,>=1.15.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-containerregistry>=2.0.0->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.15.0)\n",
            "Requirement already satisfied: numpy!=1.19.3 in /usr/local/lib/python3.7/dist-packages (from azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (1.18.5)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (3.0.0)\n",
            "Requirement already satisfied: azureml-dataprep<2.19.0a,>=2.18.0a in /usr/local/lib/python3.7/dist-packages (from azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (2.18.0)\n",
            "Requirement already satisfied: fusepy<4.0.0,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (3.0.1)\n",
            "Requirement already satisfied: dotnetcore2<3.0.0,>=2.1.14 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<2.19.0a,>=2.18.0a->azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (2.1.21)\n",
            "Requirement already satisfied: azureml-dataprep-native<37.0.0,>=36.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<2.19.0a,>=2.18.0a->azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (36.0.0)\n",
            "Requirement already satisfied: cloudpickle<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<2.19.0a,>=2.18.0a->azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (1.3.0)\n",
            "Requirement already satisfied: azureml-dataprep-rslex<1.17.0a,>=1.16.0dev0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<2.19.0a,>=2.18.0a->azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (1.16.1)\n",
            "Requirement already satisfied: azure-identity<1.5.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from azureml-dataprep<2.19.0a,>=2.18.0a->azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (1.4.1)\n",
            "Requirement already satisfied: msal<2.0.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from azure-identity<1.5.0,>=1.2.0->azureml-dataprep<2.19.0a,>=2.18.0a->azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (1.13.0)\n",
            "Requirement already satisfied: msal-extensions~=0.2.2 in /usr/local/lib/python3.7/dist-packages (from azure-identity<1.5.0,>=1.2.0->azureml-dataprep<2.19.0a,>=2.18.0a->azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (0.2.2)\n",
            "Requirement already satisfied: azureml-pipeline-steps~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-pipeline~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-train-core~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-pipeline-steps~=1.32.0->azureml-pipeline~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-automl-core~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-train-automl-runtime~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-automl-runtime~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azureml-telemetry~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-core~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: pandas<1.0.0,>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.25.3)\n",
            "Requirement already satisfied: onnxruntime<=1.8.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.8.0)\n",
            "Requirement already satisfied: sklearn-pandas<=1.7.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.7.0)\n",
            "Requirement already satisfied: scikit-learn<0.23.0,>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.22.2.post1)\n",
            "Requirement already satisfied: statsmodels<=0.10.2,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.10.2)\n",
            "Requirement already satisfied: keras2onnx<=1.6.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.6.0)\n",
            "Requirement already satisfied: dill<0.4.0,>=0.2.8 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.3.4)\n",
            "Requirement already satisfied: nimbusml<=1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.8.0)\n",
            "Requirement already satisfied: smart-open<=1.9.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.9.0)\n",
            "Requirement already satisfied: botocore<=1.18.18 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.18.18)\n",
            "Requirement already satisfied: boto3<=1.15.18 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.15.18)\n",
            "Requirement already satisfied: scipy<=1.5.2,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.4.1)\n",
            "Requirement already satisfied: onnxconverter-common<=1.6.0,>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.6.0)\n",
            "Requirement already satisfied: onnx<=1.7.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.7.0)\n",
            "Requirement already satisfied: lightgbm<=2.3.0,>=2.0.11 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (2.2.3)\n",
            "Requirement already satisfied: onnxmltools==1.4.1 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.4.1)\n",
            "Requirement already satisfied: pmdarima==1.1.1 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.1.1)\n",
            "Requirement already satisfied: gensim<3.9.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (3.6.0)\n",
            "Requirement already satisfied: psutil<6.0.0,>=5.2.2 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (5.8.0)\n",
            "Requirement already satisfied: joblib==0.14.1 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.14.1)\n",
            "Requirement already satisfied: py-cpuinfo==5.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (5.0.0)\n",
            "Requirement already satisfied: skl2onnx==1.4.9 in /usr/local/lib/python3.7/dist-packages (from azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.4.9)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxmltools==1.4.1->azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (3.17.3)\n",
            "Requirement already satisfied: Cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima==1.1.1->azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.29.23)\n",
            "Requirement already satisfied: applicationinsights in /usr/local/lib/python3.7/dist-packages (from azureml-telemetry~=1.32.0->azureml-automl-core~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.11.10)\n",
            "Requirement already satisfied: azureml-defaults~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: jinja2<=2.11.2 in /usr/local/lib/python3.7/dist-packages (from azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (2.11.2)\n",
            "Requirement already satisfied: azureml-interpret~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: azure-storage-queue~=12.1 in /usr/local/lib/python3.7/dist-packages (from azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (12.1.6)\n",
            "Requirement already satisfied: flask==1.0.3 in /usr/local/lib/python3.7/dist-packages (from azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.0.3)\n",
            "Requirement already satisfied: configparser==3.7.4 in /usr/local/lib/python3.7/dist-packages (from azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (3.7.4)\n",
            "Requirement already satisfied: azureml-model-management-sdk==1.0.1b6.post1 in /usr/local/lib/python3.7/dist-packages (from azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.0.1b6.post1)\n",
            "Requirement already satisfied: gunicorn==20.1.0 in /usr/local/lib/python3.7/dist-packages (from azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (20.1.0)\n",
            "Requirement already satisfied: opencensus-ext-azure==1.0.8 in /usr/local/lib/python3.7/dist-packages (from azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.0.8)\n",
            "Requirement already satisfied: werkzeug<=1.0.1,>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.0.1)\n",
            "Requirement already satisfied: json-logging-py==0.2 in /usr/local/lib/python3.7/dist-packages (from azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.2)\n",
            "Requirement already satisfied: liac-arff>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (2.5.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask==1.0.3->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.0.3->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (7.1.2)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn==20.1.0->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (57.2.0)\n",
            "Requirement already satisfied: opencensus<1.0.0,>=0.7.13 in /usr/local/lib/python3.7/dist-packages (from opencensus-ext-azure==1.0.8->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.7.13)\n",
            "Requirement already satisfied: interpret-community==0.18.* in /usr/local/lib/python3.7/dist-packages (from azureml-interpret~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.18.1)\n",
            "Requirement already satisfied: shap<=0.39.0,>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from interpret-community==0.18.*->azureml-interpret~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.39.0)\n",
            "Requirement already satisfied: interpret-core[required]<=0.2.4,>=0.1.20 in /usr/local/lib/python3.7/dist-packages (from interpret-community==0.18.*->azureml-interpret~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from interpret-community==0.18.*->azureml-interpret~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (21.0)\n",
            "Requirement already satisfied: azureml-train-restclients-hyperdrive~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from azureml-train-core~=1.32.0->azureml-pipeline-steps~=1.32.0->azureml-pipeline~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (7.6.3)\n",
            "Requirement already satisfied: azure-storage-blob>=12.6.0 in /usr/local/lib/python3.7/dist-packages (from azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (12.8.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3<=1.15.18->azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.3.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (2.20)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker<5.0.0->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.1.0)\n",
            "Requirement already satisfied: distro>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from dotnetcore2<3.0.0,>=2.1.14->azureml-dataprep<2.19.0a,>=2.18.0a->azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (1.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (5.0.5)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (3.5.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (2.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<=2.11.2->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle<3.0.0->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (4.6.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.7/dist-packages (from keras2onnx<=1.6.0,>=1.4.0->azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.4.0)\n",
            "Requirement already satisfied: portalocker~=1.0 in /usr/local/lib/python3.7/dist-packages (from msal-extensions~=0.2.2->azure-identity<1.5.0,>=1.2.0->azureml-dataprep<2.19.0a,>=2.18.0a->azureml-dataset-runtime[fuse]~=1.32.0->azureml-sdk[automl,notebooks]) (1.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (2021.5.30)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.3.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (3.3.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (4.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (2.6.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ndg-httpsclient<=0.5.1->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx<=1.7.0,>=1.6.0->azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,>=1.3.0->azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.12)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus<1.0.0,>=0.7.13->opencensus-ext-azure==1.0.8->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.26.3)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus<1.0.0,>=0.7.13->opencensus-ext-azure==1.0.8->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.1.2)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus<1.0.0,>=0.7.13->opencensus-ext-azure==1.0.8->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.32.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus<1.0.0,>=0.7.13->opencensus-ext-azure==1.0.8->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.53.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus<1.0.0,>=0.7.13->opencensus-ext-azure==1.0.8->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus<1.0.0,>=0.7.13->opencensus-ext-azure==1.0.8->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus<1.0.0,>=0.7.13->opencensus-ext-azure==1.0.8->azureml-defaults~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (4.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->interpret-community==0.18.*->azureml-interpret~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (2.4.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from papermill<2->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (3.13)\n",
            "Requirement already satisfied: ansiwrap in /usr/local/lib/python3.7/dist-packages (from papermill<2->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.8.4)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.7/dist-packages (from papermill<2->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (4.41.1)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.7/dist-packages (from papermill<2->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (8.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from papermill<2->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest<1.0.0,>=0.5.1->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (3.1.1)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml<0.17.5,>=0.15.35->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.2.6)\n",
            "Requirement already satisfied: jeepney>=0.6 in /usr/local/lib/python3.7/dist-packages (from SecretStorage<4.0.0->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (0.7.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap<=0.39.0,>=0.20.0->interpret-community==0.18.*->azureml-interpret~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap<=0.39.0,>=0.20.0->interpret-community==0.18.*->azureml-interpret~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.51.2)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.7/dist-packages (from smart-open<=1.9.0->azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (2.49.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels<=0.10.2,>=0.9.0->azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.5.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (5.3.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (0.10.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (1.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.32.0->azureml-sdk[automl,notebooks]) (0.7.0)\n",
            "Requirement already satisfied: textwrap3>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from ansiwrap->papermill<2->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.9.2)\n",
            "Requirement already satisfied: backports.weakref in /usr/local/lib/python3.7/dist-packages (from backports.tempfile->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (1.0.post1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6->azureml-contrib-notebook~=1.32.0->azureml-sdk[automl,notebooks]) (0.5.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->keras2onnx<=1.6.0,>=1.4.0->azureml-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (1.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle<3.0.0->azureml-core~=1.32.0->azureml-sdk[automl,notebooks]) (3.5.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap<=0.39.0,>=0.20.0->interpret-community==0.18.*->azureml-interpret~=1.32.0->azureml-train-automl-runtime~=1.32.0->azureml-train-automl~=1.32.0->azureml-sdk[automl,notebooks]) (0.34.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSFGetHNYpgp",
        "outputId": "f1b92c3c-734b-420b-8f7a-f3e4347bcc6e"
      },
      "source": [
        "import pickle\n",
        "with open('model.pkl', 'br') as p:\n",
        "  model = pickle.load(p, encoding='utf-8')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType' from 'azureml.automl.core._run.types' (/usr/local/lib/python3.7/dist-packages/azureml/automl/core/_run/types.py).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGZM2ChjV8RZ",
        "outputId": "4a01521f-f482-4acf-b54a-54a91b683bf8"
      },
      "source": [
        "type(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "azureml.automl.runtime.shared.model_wrappers.RegressionPipeline"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWfuizvtdofM",
        "outputId": "32dfcde5-c833-4c2b-d517-09da10c7a7a3"
      },
      "source": [
        "dir(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_estimator_type',\n",
              " '_final_estimator',\n",
              " '_fit',\n",
              " '_get_ci',\n",
              " '_get_param_names',\n",
              " '_get_params',\n",
              " '_get_tags',\n",
              " '_inverse_transform',\n",
              " '_iter',\n",
              " '_log_message',\n",
              " '_more_tags',\n",
              " '_pairwise',\n",
              " '_quantiles',\n",
              " '_replace_estimator',\n",
              " '_required_parameters',\n",
              " '_set_params',\n",
              " '_stddev',\n",
              " '_transform',\n",
              " '_validate_names',\n",
              " '_validate_steps',\n",
              " 'classes_',\n",
              " 'decision_function',\n",
              " 'fit',\n",
              " 'fit_predict',\n",
              " 'fit_transform',\n",
              " 'get_params',\n",
              " 'inverse_transform',\n",
              " 'memory',\n",
              " 'named_steps',\n",
              " 'pipeline',\n",
              " 'predict',\n",
              " 'predict_log_proba',\n",
              " 'predict_proba',\n",
              " 'predict_quantiles',\n",
              " 'quantiles',\n",
              " 'score',\n",
              " 'score_samples',\n",
              " 'set_params',\n",
              " 'stddev',\n",
              " 'steps',\n",
              " 'transform',\n",
              " 'verbose']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwok3KltdsCM",
        "outputId": "8e6428e1-c6ca-47f0-f775-d6e1c70b7c6e"
      },
      "source": [
        "params = model.get_params()\n",
        "params"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'datatransformer': DataTransformer(\n",
              "     task='regression',\n",
              "     is_onnx_compatible=False,\n",
              "     enable_feature_sweeping=True,\n",
              "     enable_dnn=False,\n",
              "     force_text_dnn=False,\n",
              "     feature_sweeping_timeout=86400,\n",
              "     featurization_config=None,\n",
              "     is_cross_validation=True,\n",
              "     feature_sweeping_config={}\n",
              " ),\n",
              " 'datatransformer__enable_dnn': False,\n",
              " 'datatransformer__enable_feature_sweeping': True,\n",
              " 'datatransformer__feature_sweeping_config': {},\n",
              " 'datatransformer__feature_sweeping_timeout': 86400,\n",
              " 'datatransformer__featurization_config': None,\n",
              " 'datatransformer__force_text_dnn': False,\n",
              " 'datatransformer__is_cross_validation': True,\n",
              " 'datatransformer__is_onnx_compatible': False,\n",
              " 'datatransformer__observer': None,\n",
              " 'datatransformer__task': 'regression',\n",
              " 'datatransformer__working_dir': '/content',\n",
              " 'pipeline': Pipeline(memory=None,\n",
              "          steps=[('datatransformer',\n",
              "                  DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='regression', working_dir='/content')),\n",
              "                 ('prefittedsoftvotingregresso...\n",
              " )), ('elasticnet', ElasticNet(alpha=0.05357894736842105, copy_X=True, fit_intercept=True, l1_ratio=0.6352631578947369, max_iter=1000, normalize=False, positive=False, precompute=False, random_state=None, selection='cyclic', tol=0.0001, warm_start=False))], verbose=False))], weights=[0.4, 0.13333333333333333, 0.26666666666666666, 0.06666666666666667, 0.13333333333333333]))],\n",
              "          verbose=False),\n",
              " 'pipeline__datatransformer': DataTransformer(\n",
              "     task='regression',\n",
              "     is_onnx_compatible=False,\n",
              "     enable_feature_sweeping=True,\n",
              "     enable_dnn=False,\n",
              "     force_text_dnn=False,\n",
              "     feature_sweeping_timeout=86400,\n",
              "     featurization_config=None,\n",
              "     is_cross_validation=True,\n",
              "     feature_sweeping_config={}\n",
              " ),\n",
              " 'pipeline__datatransformer__enable_dnn': False,\n",
              " 'pipeline__datatransformer__enable_feature_sweeping': True,\n",
              " 'pipeline__datatransformer__feature_sweeping_config': {},\n",
              " 'pipeline__datatransformer__feature_sweeping_timeout': 86400,\n",
              " 'pipeline__datatransformer__featurization_config': None,\n",
              " 'pipeline__datatransformer__force_text_dnn': False,\n",
              " 'pipeline__datatransformer__is_cross_validation': True,\n",
              " 'pipeline__datatransformer__is_onnx_compatible': False,\n",
              " 'pipeline__datatransformer__observer': None,\n",
              " 'pipeline__datatransformer__task': 'regression',\n",
              " 'pipeline__datatransformer__working_dir': '/content',\n",
              " 'pipeline__memory': None,\n",
              " 'pipeline__prefittedsoftvotingregressor': PreFittedSoftVotingRegressor(\n",
              "     estimators=[('1', Pipeline(memory=None,\n",
              "              steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                     ('xgboostregressor',\n",
              "                      XGBoostRegressor(n_jobs=-1, problem_info=ProblemInfo(\n",
              "         dataset_samples=1460,\n",
              "         dataset_features=456,\n",
              "         dataset_classes=None,\n",
              "         dataset_num_categorical=0,\n",
              "         dataset_categoricals=None,\n",
              "         pipeline_categoricals=None,\n",
              "         dataset_y_std=79415.29188606751,\n",
              "         dataset_uid=None,\n",
              "         subsampling=False,...\n",
              "         subsampling_schedule='hyperband_clip',\n",
              "         cost_mode_param=None,\n",
              "         iteration_timeout_mode=0,\n",
              "         iteration_timeout_param=None,\n",
              "         feature_column_names=None,\n",
              "         label_column_name=None,\n",
              "         weight_column_name=None,\n",
              "         cv_split_column_names=None,\n",
              "         enable_streaming=None,\n",
              "         timeseries_param_dict=None,\n",
              "         gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "     ), random_state=0, tree_method='auto'))],\n",
              "              verbose=False)), ('0', Pipeline(memory=None,\n",
              "              steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                     ('lightgbmregressor',\n",
              "                      LightGBMRegressor(min_data_in_leaf=20, n_jobs=-1, problem_info=ProblemInfo(\n",
              "         dataset_samples=1460,\n",
              "         dataset_features=456,\n",
              "         dataset_classes=None,\n",
              "         dataset_num_categorical=0,\n",
              "         dataset_categoricals=None,\n",
              "         pipeline_categoricals=None,\n",
              "         dataset_y_std=79415.29188606751,\n",
              "         dataset_uid=N...\n",
              "         subsampling_schedule='hyperband_clip',\n",
              "         cost_mode_param=None,\n",
              "         iteration_timeout_mode=0,\n",
              "         iteration_timeout_param=None,\n",
              "         feature_column_names=None,\n",
              "         label_column_name=None,\n",
              "         weight_column_name=None,\n",
              "         cv_split_column_names=None,\n",
              "         enable_streaming=None,\n",
              "         timeseries_param_dict=None,\n",
              "         gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "     ), random_state=None))],\n",
              "              verbose=False)), ('30', Pipeline(memory=None,\n",
              "              steps=[('sparsenormalizer', Normalizer(copy=True, norm='l1')),\n",
              "                     ('xgboostregressor',\n",
              "                      XGBoostRegressor(booster='gbtree', colsample_bytree=0.8, eta=0.4, gamma=0.01, max_depth=6, max_leaves=0, n_estimators=800, n_jobs=-1, objective='reg:linear', problem_info=ProblemInfo(\n",
              "         dataset_samples=1460,\n",
              "         dataset_features=456,\n",
              "         dataset_classes=None,\n",
              "         dataset_num_...\n",
              "         iteration_timeout_mode=0,\n",
              "         iteration_timeout_param=None,\n",
              "         feature_column_names=None,\n",
              "         label_column_name=None,\n",
              "         weight_column_name=None,\n",
              "         cv_split_column_names=None,\n",
              "         enable_streaming=None,\n",
              "         timeseries_param_dict=None,\n",
              "         gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "     ), random_state=0, reg_alpha=0, reg_lambda=2.291666666666667, subsample=0.7, tree_method='auto'))],\n",
              "              verbose=False)), ('20', Pipeline(memory=None,\n",
              "              steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                     ('sgdregressor',\n",
              "                      SGDRegressor(alpha=0.0001, average=False, early_stopping=False,\n",
              "                                   epsilon=0.03681632653061225, eta0=0.01,\n",
              "                                   fit_intercept=True, l1_ratio=0.4081632653061224,\n",
              "                                   learning_rate='invscaling', loss='squared_loss',\n",
              "                                   max_iter=100, n_iter_no_change=5, penalty='l2',\n",
              "                                   power_t=0.25, random_state=None, shuffle=True,\n",
              "                                   tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                                   warm_start=False))],\n",
              "              verbose=False)), ('2', Pipeline(memory=None,\n",
              "              steps=[('standardscalerwrapper',\n",
              "                      StandardScalerWrapper(\n",
              "         copy=True,\n",
              "         with_mean=False,\n",
              "         with_std=True\n",
              "     )),\n",
              "                     ('elasticnet',\n",
              "                      ElasticNet(alpha=0.05357894736842105, copy_X=True,\n",
              "                                 fit_intercept=True, l1_ratio=0.6352631578947369,\n",
              "                                 max_iter=1000, normalize=False, positive=False,\n",
              "                                 precompute=False, random_state=None,\n",
              "                                 selection='cyclic', tol=0.0001,\n",
              "                                 warm_start=False))],\n",
              "              verbose=False))],\n",
              "     weights=[0.4, 0.13333333333333333, 0.26666666666666666, 0.06666666666666667, 0.13333333333333333]\n",
              " ),\n",
              " 'pipeline__prefittedsoftvotingregressor__estimators': [('1',\n",
              "   Pipeline(memory=None,\n",
              "            steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                   ('xgboostregressor',\n",
              "                    XGBoostRegressor(n_jobs=-1, problem_info=ProblemInfo(\n",
              "       dataset_samples=1460,\n",
              "       dataset_features=456,\n",
              "       dataset_classes=None,\n",
              "       dataset_num_categorical=0,\n",
              "       dataset_categoricals=None,\n",
              "       pipeline_categoricals=None,\n",
              "       dataset_y_std=79415.29188606751,\n",
              "       dataset_uid=None,\n",
              "       subsampling=False,...\n",
              "       subsampling_schedule='hyperband_clip',\n",
              "       cost_mode_param=None,\n",
              "       iteration_timeout_mode=0,\n",
              "       iteration_timeout_param=None,\n",
              "       feature_column_names=None,\n",
              "       label_column_name=None,\n",
              "       weight_column_name=None,\n",
              "       cv_split_column_names=None,\n",
              "       enable_streaming=None,\n",
              "       timeseries_param_dict=None,\n",
              "       gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "   ), random_state=0, tree_method='auto'))],\n",
              "            verbose=False)),\n",
              "  ('0', Pipeline(memory=None,\n",
              "            steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                   ('lightgbmregressor',\n",
              "                    LightGBMRegressor(min_data_in_leaf=20, n_jobs=-1, problem_info=ProblemInfo(\n",
              "       dataset_samples=1460,\n",
              "       dataset_features=456,\n",
              "       dataset_classes=None,\n",
              "       dataset_num_categorical=0,\n",
              "       dataset_categoricals=None,\n",
              "       pipeline_categoricals=None,\n",
              "       dataset_y_std=79415.29188606751,\n",
              "       dataset_uid=N...\n",
              "       subsampling_schedule='hyperband_clip',\n",
              "       cost_mode_param=None,\n",
              "       iteration_timeout_mode=0,\n",
              "       iteration_timeout_param=None,\n",
              "       feature_column_names=None,\n",
              "       label_column_name=None,\n",
              "       weight_column_name=None,\n",
              "       cv_split_column_names=None,\n",
              "       enable_streaming=None,\n",
              "       timeseries_param_dict=None,\n",
              "       gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "   ), random_state=None))],\n",
              "            verbose=False)),\n",
              "  ('30', Pipeline(memory=None,\n",
              "            steps=[('sparsenormalizer', Normalizer(copy=True, norm='l1')),\n",
              "                   ('xgboostregressor',\n",
              "                    XGBoostRegressor(booster='gbtree', colsample_bytree=0.8, eta=0.4, gamma=0.01, max_depth=6, max_leaves=0, n_estimators=800, n_jobs=-1, objective='reg:linear', problem_info=ProblemInfo(\n",
              "       dataset_samples=1460,\n",
              "       dataset_features=456,\n",
              "       dataset_classes=None,\n",
              "       dataset_num_...\n",
              "       iteration_timeout_mode=0,\n",
              "       iteration_timeout_param=None,\n",
              "       feature_column_names=None,\n",
              "       label_column_name=None,\n",
              "       weight_column_name=None,\n",
              "       cv_split_column_names=None,\n",
              "       enable_streaming=None,\n",
              "       timeseries_param_dict=None,\n",
              "       gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "   ), random_state=0, reg_alpha=0, reg_lambda=2.291666666666667, subsample=0.7, tree_method='auto'))],\n",
              "            verbose=False)),\n",
              "  ('20', Pipeline(memory=None,\n",
              "            steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                   ('sgdregressor',\n",
              "                    SGDRegressor(alpha=0.0001, average=False, early_stopping=False,\n",
              "                                 epsilon=0.03681632653061225, eta0=0.01,\n",
              "                                 fit_intercept=True, l1_ratio=0.4081632653061224,\n",
              "                                 learning_rate='invscaling', loss='squared_loss',\n",
              "                                 max_iter=100, n_iter_no_change=5, penalty='l2',\n",
              "                                 power_t=0.25, random_state=None, shuffle=True,\n",
              "                                 tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                                 warm_start=False))],\n",
              "            verbose=False)),\n",
              "  ('2', Pipeline(memory=None,\n",
              "            steps=[('standardscalerwrapper',\n",
              "                    StandardScalerWrapper(\n",
              "       copy=True,\n",
              "       with_mean=False,\n",
              "       with_std=True\n",
              "   )),\n",
              "                   ('elasticnet',\n",
              "                    ElasticNet(alpha=0.05357894736842105, copy_X=True,\n",
              "                               fit_intercept=True, l1_ratio=0.6352631578947369,\n",
              "                               max_iter=1000, normalize=False, positive=False,\n",
              "                               precompute=False, random_state=None,\n",
              "                               selection='cyclic', tol=0.0001,\n",
              "                               warm_start=False))],\n",
              "            verbose=False))],\n",
              " 'pipeline__prefittedsoftvotingregressor__weights': [0.4,\n",
              "  0.13333333333333333,\n",
              "  0.26666666666666666,\n",
              "  0.06666666666666667,\n",
              "  0.13333333333333333],\n",
              " 'pipeline__steps': [('datatransformer', DataTransformer(\n",
              "       task='regression',\n",
              "       is_onnx_compatible=False,\n",
              "       enable_feature_sweeping=True,\n",
              "       enable_dnn=False,\n",
              "       force_text_dnn=False,\n",
              "       feature_sweeping_timeout=86400,\n",
              "       featurization_config=None,\n",
              "       is_cross_validation=True,\n",
              "       feature_sweeping_config={}\n",
              "   )), ('prefittedsoftvotingregressor', PreFittedSoftVotingRegressor(\n",
              "       estimators=[('1', Pipeline(memory=None,\n",
              "                steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                       ('xgboostregressor',\n",
              "                        XGBoostRegressor(n_jobs=-1, problem_info=ProblemInfo(\n",
              "           dataset_samples=1460,\n",
              "           dataset_features=456,\n",
              "           dataset_classes=None,\n",
              "           dataset_num_categorical=0,\n",
              "           dataset_categoricals=None,\n",
              "           pipeline_categoricals=None,\n",
              "           dataset_y_std=79415.29188606751,\n",
              "           dataset_uid=None,\n",
              "           subsampling=False,...\n",
              "           subsampling_schedule='hyperband_clip',\n",
              "           cost_mode_param=None,\n",
              "           iteration_timeout_mode=0,\n",
              "           iteration_timeout_param=None,\n",
              "           feature_column_names=None,\n",
              "           label_column_name=None,\n",
              "           weight_column_name=None,\n",
              "           cv_split_column_names=None,\n",
              "           enable_streaming=None,\n",
              "           timeseries_param_dict=None,\n",
              "           gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "       ), random_state=0, tree_method='auto'))],\n",
              "                verbose=False)), ('0', Pipeline(memory=None,\n",
              "                steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                       ('lightgbmregressor',\n",
              "                        LightGBMRegressor(min_data_in_leaf=20, n_jobs=-1, problem_info=ProblemInfo(\n",
              "           dataset_samples=1460,\n",
              "           dataset_features=456,\n",
              "           dataset_classes=None,\n",
              "           dataset_num_categorical=0,\n",
              "           dataset_categoricals=None,\n",
              "           pipeline_categoricals=None,\n",
              "           dataset_y_std=79415.29188606751,\n",
              "           dataset_uid=N...\n",
              "           subsampling_schedule='hyperband_clip',\n",
              "           cost_mode_param=None,\n",
              "           iteration_timeout_mode=0,\n",
              "           iteration_timeout_param=None,\n",
              "           feature_column_names=None,\n",
              "           label_column_name=None,\n",
              "           weight_column_name=None,\n",
              "           cv_split_column_names=None,\n",
              "           enable_streaming=None,\n",
              "           timeseries_param_dict=None,\n",
              "           gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "       ), random_state=None))],\n",
              "                verbose=False)), ('30', Pipeline(memory=None,\n",
              "                steps=[('sparsenormalizer', Normalizer(copy=True, norm='l1')),\n",
              "                       ('xgboostregressor',\n",
              "                        XGBoostRegressor(booster='gbtree', colsample_bytree=0.8, eta=0.4, gamma=0.01, max_depth=6, max_leaves=0, n_estimators=800, n_jobs=-1, objective='reg:linear', problem_info=ProblemInfo(\n",
              "           dataset_samples=1460,\n",
              "           dataset_features=456,\n",
              "           dataset_classes=None,\n",
              "           dataset_num_...\n",
              "           iteration_timeout_mode=0,\n",
              "           iteration_timeout_param=None,\n",
              "           feature_column_names=None,\n",
              "           label_column_name=None,\n",
              "           weight_column_name=None,\n",
              "           cv_split_column_names=None,\n",
              "           enable_streaming=None,\n",
              "           timeseries_param_dict=None,\n",
              "           gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "       ), random_state=0, reg_alpha=0, reg_lambda=2.291666666666667, subsample=0.7, tree_method='auto'))],\n",
              "                verbose=False)), ('20', Pipeline(memory=None,\n",
              "                steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                       ('sgdregressor',\n",
              "                        SGDRegressor(alpha=0.0001, average=False, early_stopping=False,\n",
              "                                     epsilon=0.03681632653061225, eta0=0.01,\n",
              "                                     fit_intercept=True, l1_ratio=0.4081632653061224,\n",
              "                                     learning_rate='invscaling', loss='squared_loss',\n",
              "                                     max_iter=100, n_iter_no_change=5, penalty='l2',\n",
              "                                     power_t=0.25, random_state=None, shuffle=True,\n",
              "                                     tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                                     warm_start=False))],\n",
              "                verbose=False)), ('2', Pipeline(memory=None,\n",
              "                steps=[('standardscalerwrapper',\n",
              "                        StandardScalerWrapper(\n",
              "           copy=True,\n",
              "           with_mean=False,\n",
              "           with_std=True\n",
              "       )),\n",
              "                       ('elasticnet',\n",
              "                        ElasticNet(alpha=0.05357894736842105, copy_X=True,\n",
              "                                   fit_intercept=True, l1_ratio=0.6352631578947369,\n",
              "                                   max_iter=1000, normalize=False, positive=False,\n",
              "                                   precompute=False, random_state=None,\n",
              "                                   selection='cyclic', tol=0.0001,\n",
              "                                   warm_start=False))],\n",
              "                verbose=False))],\n",
              "       weights=[0.4, 0.13333333333333333, 0.26666666666666666, 0.06666666666666667, 0.13333333333333333]\n",
              "   ))],\n",
              " 'pipeline__verbose': False,\n",
              " 'prefittedsoftvotingregressor': PreFittedSoftVotingRegressor(\n",
              "     estimators=[('1', Pipeline(memory=None,\n",
              "              steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                     ('xgboostregressor',\n",
              "                      XGBoostRegressor(n_jobs=-1, problem_info=ProblemInfo(\n",
              "         dataset_samples=1460,\n",
              "         dataset_features=456,\n",
              "         dataset_classes=None,\n",
              "         dataset_num_categorical=0,\n",
              "         dataset_categoricals=None,\n",
              "         pipeline_categoricals=None,\n",
              "         dataset_y_std=79415.29188606751,\n",
              "         dataset_uid=None,\n",
              "         subsampling=False,...\n",
              "         subsampling_schedule='hyperband_clip',\n",
              "         cost_mode_param=None,\n",
              "         iteration_timeout_mode=0,\n",
              "         iteration_timeout_param=None,\n",
              "         feature_column_names=None,\n",
              "         label_column_name=None,\n",
              "         weight_column_name=None,\n",
              "         cv_split_column_names=None,\n",
              "         enable_streaming=None,\n",
              "         timeseries_param_dict=None,\n",
              "         gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "     ), random_state=0, tree_method='auto'))],\n",
              "              verbose=False)), ('0', Pipeline(memory=None,\n",
              "              steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                     ('lightgbmregressor',\n",
              "                      LightGBMRegressor(min_data_in_leaf=20, n_jobs=-1, problem_info=ProblemInfo(\n",
              "         dataset_samples=1460,\n",
              "         dataset_features=456,\n",
              "         dataset_classes=None,\n",
              "         dataset_num_categorical=0,\n",
              "         dataset_categoricals=None,\n",
              "         pipeline_categoricals=None,\n",
              "         dataset_y_std=79415.29188606751,\n",
              "         dataset_uid=N...\n",
              "         subsampling_schedule='hyperband_clip',\n",
              "         cost_mode_param=None,\n",
              "         iteration_timeout_mode=0,\n",
              "         iteration_timeout_param=None,\n",
              "         feature_column_names=None,\n",
              "         label_column_name=None,\n",
              "         weight_column_name=None,\n",
              "         cv_split_column_names=None,\n",
              "         enable_streaming=None,\n",
              "         timeseries_param_dict=None,\n",
              "         gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "     ), random_state=None))],\n",
              "              verbose=False)), ('30', Pipeline(memory=None,\n",
              "              steps=[('sparsenormalizer', Normalizer(copy=True, norm='l1')),\n",
              "                     ('xgboostregressor',\n",
              "                      XGBoostRegressor(booster='gbtree', colsample_bytree=0.8, eta=0.4, gamma=0.01, max_depth=6, max_leaves=0, n_estimators=800, n_jobs=-1, objective='reg:linear', problem_info=ProblemInfo(\n",
              "         dataset_samples=1460,\n",
              "         dataset_features=456,\n",
              "         dataset_classes=None,\n",
              "         dataset_num_...\n",
              "         iteration_timeout_mode=0,\n",
              "         iteration_timeout_param=None,\n",
              "         feature_column_names=None,\n",
              "         label_column_name=None,\n",
              "         weight_column_name=None,\n",
              "         cv_split_column_names=None,\n",
              "         enable_streaming=None,\n",
              "         timeseries_param_dict=None,\n",
              "         gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "     ), random_state=0, reg_alpha=0, reg_lambda=2.291666666666667, subsample=0.7, tree_method='auto'))],\n",
              "              verbose=False)), ('20', Pipeline(memory=None,\n",
              "              steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                     ('sgdregressor',\n",
              "                      SGDRegressor(alpha=0.0001, average=False, early_stopping=False,\n",
              "                                   epsilon=0.03681632653061225, eta0=0.01,\n",
              "                                   fit_intercept=True, l1_ratio=0.4081632653061224,\n",
              "                                   learning_rate='invscaling', loss='squared_loss',\n",
              "                                   max_iter=100, n_iter_no_change=5, penalty='l2',\n",
              "                                   power_t=0.25, random_state=None, shuffle=True,\n",
              "                                   tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                                   warm_start=False))],\n",
              "              verbose=False)), ('2', Pipeline(memory=None,\n",
              "              steps=[('standardscalerwrapper',\n",
              "                      StandardScalerWrapper(\n",
              "         copy=True,\n",
              "         with_mean=False,\n",
              "         with_std=True\n",
              "     )),\n",
              "                     ('elasticnet',\n",
              "                      ElasticNet(alpha=0.05357894736842105, copy_X=True,\n",
              "                                 fit_intercept=True, l1_ratio=0.6352631578947369,\n",
              "                                 max_iter=1000, normalize=False, positive=False,\n",
              "                                 precompute=False, random_state=None,\n",
              "                                 selection='cyclic', tol=0.0001,\n",
              "                                 warm_start=False))],\n",
              "              verbose=False))],\n",
              "     weights=[0.4, 0.13333333333333333, 0.26666666666666666, 0.06666666666666667, 0.13333333333333333]\n",
              " ),\n",
              " 'prefittedsoftvotingregressor__estimators': [('1', Pipeline(memory=None,\n",
              "            steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                   ('xgboostregressor',\n",
              "                    XGBoostRegressor(n_jobs=-1, problem_info=ProblemInfo(\n",
              "       dataset_samples=1460,\n",
              "       dataset_features=456,\n",
              "       dataset_classes=None,\n",
              "       dataset_num_categorical=0,\n",
              "       dataset_categoricals=None,\n",
              "       pipeline_categoricals=None,\n",
              "       dataset_y_std=79415.29188606751,\n",
              "       dataset_uid=None,\n",
              "       subsampling=False,...\n",
              "       subsampling_schedule='hyperband_clip',\n",
              "       cost_mode_param=None,\n",
              "       iteration_timeout_mode=0,\n",
              "       iteration_timeout_param=None,\n",
              "       feature_column_names=None,\n",
              "       label_column_name=None,\n",
              "       weight_column_name=None,\n",
              "       cv_split_column_names=None,\n",
              "       enable_streaming=None,\n",
              "       timeseries_param_dict=None,\n",
              "       gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "   ), random_state=0, tree_method='auto'))],\n",
              "            verbose=False)), ('0', Pipeline(memory=None,\n",
              "            steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                   ('lightgbmregressor',\n",
              "                    LightGBMRegressor(min_data_in_leaf=20, n_jobs=-1, problem_info=ProblemInfo(\n",
              "       dataset_samples=1460,\n",
              "       dataset_features=456,\n",
              "       dataset_classes=None,\n",
              "       dataset_num_categorical=0,\n",
              "       dataset_categoricals=None,\n",
              "       pipeline_categoricals=None,\n",
              "       dataset_y_std=79415.29188606751,\n",
              "       dataset_uid=N...\n",
              "       subsampling_schedule='hyperband_clip',\n",
              "       cost_mode_param=None,\n",
              "       iteration_timeout_mode=0,\n",
              "       iteration_timeout_param=None,\n",
              "       feature_column_names=None,\n",
              "       label_column_name=None,\n",
              "       weight_column_name=None,\n",
              "       cv_split_column_names=None,\n",
              "       enable_streaming=None,\n",
              "       timeseries_param_dict=None,\n",
              "       gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "   ), random_state=None))],\n",
              "            verbose=False)), ('30', Pipeline(memory=None,\n",
              "            steps=[('sparsenormalizer', Normalizer(copy=True, norm='l1')),\n",
              "                   ('xgboostregressor',\n",
              "                    XGBoostRegressor(booster='gbtree', colsample_bytree=0.8, eta=0.4, gamma=0.01, max_depth=6, max_leaves=0, n_estimators=800, n_jobs=-1, objective='reg:linear', problem_info=ProblemInfo(\n",
              "       dataset_samples=1460,\n",
              "       dataset_features=456,\n",
              "       dataset_classes=None,\n",
              "       dataset_num_...\n",
              "       iteration_timeout_mode=0,\n",
              "       iteration_timeout_param=None,\n",
              "       feature_column_names=None,\n",
              "       label_column_name=None,\n",
              "       weight_column_name=None,\n",
              "       cv_split_column_names=None,\n",
              "       enable_streaming=None,\n",
              "       timeseries_param_dict=None,\n",
              "       gpu_training_param_dict={'processing_unit_type': 'cpu'}\n",
              "   ), random_state=0, reg_alpha=0, reg_lambda=2.291666666666667, subsample=0.7, tree_method='auto'))],\n",
              "            verbose=False)), ('20', Pipeline(memory=None,\n",
              "            steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
              "                   ('sgdregressor',\n",
              "                    SGDRegressor(alpha=0.0001, average=False, early_stopping=False,\n",
              "                                 epsilon=0.03681632653061225, eta0=0.01,\n",
              "                                 fit_intercept=True, l1_ratio=0.4081632653061224,\n",
              "                                 learning_rate='invscaling', loss='squared_loss',\n",
              "                                 max_iter=100, n_iter_no_change=5, penalty='l2',\n",
              "                                 power_t=0.25, random_state=None, shuffle=True,\n",
              "                                 tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                                 warm_start=False))],\n",
              "            verbose=False)), ('2', Pipeline(memory=None,\n",
              "            steps=[('standardscalerwrapper',\n",
              "                    StandardScalerWrapper(\n",
              "       copy=True,\n",
              "       with_mean=False,\n",
              "       with_std=True\n",
              "   )),\n",
              "                   ('elasticnet',\n",
              "                    ElasticNet(alpha=0.05357894736842105, copy_X=True,\n",
              "                               fit_intercept=True, l1_ratio=0.6352631578947369,\n",
              "                               max_iter=1000, normalize=False, positive=False,\n",
              "                               precompute=False, random_state=None,\n",
              "                               selection='cyclic', tol=0.0001,\n",
              "                               warm_start=False))],\n",
              "            verbose=False))],\n",
              " 'prefittedsoftvotingregressor__weights': [0.4,\n",
              "  0.13333333333333333,\n",
              "  0.26666666666666666,\n",
              "  0.06666666666666667,\n",
              "  0.13333333333333333],\n",
              " 'stddev': [26767.33617891325]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBpSw-Iud4Ys",
        "outputId": "3ee4c257-e021-4466-9c2c-b7850438c50c"
      },
      "source": [
        "params.keys()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['pipeline__memory', 'pipeline__steps', 'pipeline__verbose', 'pipeline__datatransformer', 'pipeline__prefittedsoftvotingregressor', 'pipeline__datatransformer__task', 'pipeline__datatransformer__is_onnx_compatible', 'pipeline__datatransformer__enable_feature_sweeping', 'pipeline__datatransformer__enable_dnn', 'pipeline__datatransformer__force_text_dnn', 'pipeline__datatransformer__feature_sweeping_timeout', 'pipeline__datatransformer__featurization_config', 'pipeline__datatransformer__is_cross_validation', 'pipeline__datatransformer__feature_sweeping_config', 'pipeline__datatransformer__observer', 'pipeline__datatransformer__working_dir', 'pipeline__prefittedsoftvotingregressor__estimators', 'pipeline__prefittedsoftvotingregressor__weights', 'pipeline', 'stddev', 'datatransformer', 'prefittedsoftvotingregressor', 'datatransformer__task', 'datatransformer__is_onnx_compatible', 'datatransformer__enable_feature_sweeping', 'datatransformer__enable_dnn', 'datatransformer__force_text_dnn', 'datatransformer__feature_sweeping_timeout', 'datatransformer__featurization_config', 'datatransformer__is_cross_validation', 'datatransformer__feature_sweeping_config', 'datatransformer__observer', 'datatransformer__working_dir', 'prefittedsoftvotingregressor__estimators', 'prefittedsoftvotingregressor__weights'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIJK581meEzs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}