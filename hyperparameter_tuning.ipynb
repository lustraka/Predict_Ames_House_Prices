{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import ames # The module for loading external data - Ames Housing dataset\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import ast\n",
        "import pickle\n",
        "\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core import Workspace, Dataset, Experiment, Model, Environment, ScriptRunConfig\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, loguniform, choice"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1628500298008
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quick-starts-ws-154042\n",
            "aml-quickstarts-154042\n",
            "southcentralus\n",
            "81cefad3-d2c9-4f77-a466-99a7f541c7bb\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1628497593426
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create compute cluster\n",
        "# Choose a name for your CPU cluster\n",
        "cpu_cluster_name = \"cpu-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InProgress.....\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1628497625026
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to load the dataset from the workspace. Otherwise, load if from Kaggle\n",
        "found = False\n",
        "ds_key = 'Ames-housing-dataset'\n",
        "ds_desc = 'Ames Housing training data.'\n",
        "\n",
        "if ds_key in ws.datasets.keys():\n",
        "    found = True\n",
        "    dataset = ws.datasets[ds_key]\n",
        "    print(f'Found registered {ds_key}, use it.')\n",
        "    \n",
        "if not found:\n",
        "    train, test = ames.load_data_clean()\n",
        "    print(f\"train.shape = {train.shape}, test.shape = {test.shape}\")\n",
        "    # Register the train dataset\n",
        "    blob = ws.get_default_datastore()\n",
        "    dataset = TabularDatasetFactory.register_pandas_dataframe(train, blob, name=ds_key, description=ds_desc)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape = (1460, 80), test.shape = (1459, 79)\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/a0f98968-2133-4d47-9c9e-247029ea8b8e/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Method register_pandas_dataframe: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1628497652512
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_xgb.py\n",
        "\"\"\"Train, evaluate and log metrics for selected ML algorithm \n",
        "in the Azure workspace context.\"\"\"\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import ames\n",
        "\n",
        "from azureml.core.run import Run\n",
        "from azureml.core import Workspace\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "ds_key = 'Ames-housing-dataset'\n",
        "dataset = ws.datasets[ds_key]\n",
        "\n",
        "train = dataset.to_pandas_dataframe()\n",
        "\n",
        "X_train, X_test = train_test_split(ames.label_encode(ames.encode_dtypes(train)))\n",
        "y_train = X_train.pop('SalePrice')\n",
        "y_test = X_test.pop('SalePrice')\n",
        "\n",
        "print(f\"X_train.shape = {X_train.shape}, X_test.shape = {X_test.shape}\")\n",
        "\n",
        "run = Run.get_context()\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--learning_rate', type=float, default=0.1,\n",
        "                   help='Step size shrinkage used in update to prevent overfiffing')\n",
        "\n",
        "parser.add_argument('--gamma', type=float, default=2,\n",
        "                   help='Minimum loss reduction required to make a further partition on a leaf node of the tree')\n",
        "\n",
        "parser.add_argument('--max_depth', type=int, default=3,\n",
        "                   help='Maximum depth of a tree')\n",
        "\n",
        "args = parser.parse_args()\n",
        "run.log('Learning rate', np.float(args.learning_rate))\n",
        "run.log('Gamma', np.float(args.gamma))\n",
        "run.log('Maximum depth', np.float(args.max_depth))\n",
        "\n",
        "model = XGBRegressor(learning_rate=args.learning_rate, gamma=args.gamma, max_depth=args.max_depth, objective='reg:squarederror')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "run.log(\"r2_score\", np.float(r2))\n",
        "print(f'Writting r2 score = {r2} into a log.')\n",
        "\n",
        "os.makedirs('./outputs', exist_ok=True)\n",
        "joblib.dump(model, './outputs/model.joblib')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_xgb.py\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#! python train_xgb.py"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape = (1095, 79), X_test.shape = (365, 79)\n",
            "Attempted to log scalar metric Learning rate:\n",
            "0.1\n",
            "Attempted to log scalar metric Gamma:\n",
            "2.0\n",
            "Attempted to log scalar metric Maximum depth:\n",
            "3.0\n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  data.base is not None and isinstance(data, np.ndarray) \\\n",
            "Attempted to log scalar metric r2_score:\n",
            "0.9165099581562921\n",
            "Writting r2 score = 0.9165099581562921 into a log.\n"
          ]
        }
      ],
      "execution_count": 50,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_env.yml\n",
        "\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- pip:\n",
        "  - azureml-defaults==1.32.0\n",
        "- scikit-learn\n",
        "- xgboost"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing conda_env.yml\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an Azure ML environment\n",
        "# Dependencies are the same as for AutoML experiment\n",
        "env = Environment.from_conda_specification(name='env', file_path='conda_env.yml')\n",
        "\n",
        "# Configure the training job\n",
        "src = ScriptRunConfig(source_directory=\".\",\n",
        "                     script='train_xgb.py',\n",
        "                     # arguments=['--learning_rate', 0.01, '--gamma', 5, '--max_depth', 5], # Just for testing\n",
        "                     compute_target=cpu_cluster,\n",
        "                     environment=env)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1628497755131
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration\n",
        "\n",
        "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598531923519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for an experiment\n",
        "experiment_name = 'Ames-housing-hdr'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1628497763802
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the script\n",
        "# run = experiment.submit(src)\n",
        "np.log(np.array([0.01, 0.2]))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "array([-4.60517019, -1.60943791])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1628500430444
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
        "# Specify a Policy\n",
        "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
        "\n",
        "#TODO: Create the different params that you will be using during training\n",
        "# Specify parameter sampler\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        '--learning_rate': loguniform(-4.6, -1.6),\n",
        "        '--gamma': uniform(0, 9), \n",
        "        '--max_depth': choice(3, 5, 7)\n",
        "    }\n",
        ")\n",
        "\n",
        "#TODO: Create your estimator and hyperdrive config\n",
        "# src - see above\n",
        "\n",
        "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                    hyperparameter_sampling=ps,\n",
        "                                    policy=policy,\n",
        "                                    primary_metric_name='r2_score',\n",
        "                                    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                    max_total_runs=20,\n",
        "                                    max_concurrent_runs=4,\n",
        "                                    max_duration_minutes=30)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1628500590713
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Submit your experiment\r\n",
        "hdr = experiment.submit(config=hyperdrive_config)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1628500598068
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show run details with the widget.\n",
        "RunDetails(hdr).show()\n",
        "hdr.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceef2351a3f5469da71ef23a939f3b8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790?wsid=/subscriptions/81cefad3-d2c9-4f77-a466-99a7f541c7bb/resourcegroups/aml-quickstarts-154042/workspaces/quick-starts-ws-154042&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790\", \"run_properties\": {\"run_id\": \"HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790\", \"created_utc\": \"2021-08-09T09:16:36.725447Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"r2_score\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"8b0edae0-a910-423c-9bd7-2b7b3b6508bf\", \"user_agent\": \"python/3.6.9 (Linux-5.4.0-1055-azure-x86_64-with-debian-buster-sid) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.32.0\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"20\", \"max_total_jobs\": \"20\", \"_aml_system_max_duration_minutes\": \"30\", \"max_duration_minutes\": \"30\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 2, \\\"delay_evaluation\\\": 0, \\\"slack_factor\\\": 0.1}}\", \"policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 2, \\\"delay_evaluation\\\": 0, \\\"slack_factor\\\": 0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--learning_rate\\\": [\\\"loguniform\\\", [-4.6, -1.6]], \\\"--gamma\\\": [\\\"uniform\\\", [0, 9]], \\\"--max_depth\\\": [\\\"choice\\\", [[3, 5, 7]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--learning_rate\\\": [\\\"loguniform\\\", [-4.6, -1.6]], \\\"--gamma\\\": [\\\"uniform\\\", [0, 9]], \\\"--max_depth\\\": [\\\"choice\\\", [[3, 5, 7]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"r2_score\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"r2_score\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/81cefad3-d2c9-4f77-a466-99a7f541c7bb/resourceGroups/aml-quickstarts-154042/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-154042/experiments/Ames-housing-hdr\\\", \\\"SubscriptionId\\\": \\\"81cefad3-d2c9-4f77-a466-99a7f541c7bb\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-154042\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-154042\\\", \\\"ExperimentName\\\": \\\"Ames-housing-hdr\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_xgb.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"cpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"env\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults==1.32.0\\\"]}, \\\"scikit-learn\\\", \\\"xgboost\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"docker\\\": {\\\"useDocker\\\": false, \\\"sharedVolumes\\\": true, \\\"arguments\\\": [], \\\"shmSize\\\": \\\"2g\\\"}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"credentialPassthrough\\\": false, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"8b0edae0-a910-423c-9bd7-2b7b3b6508bf\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"42c57e6c-31b9-4d8c-843b-47f0b5e782c3\\\", \\\"amlClientSessionId\\\": \\\"e4e301eb-3cb7-4026-9713-5d259a796ae3\\\", \\\"subscriptionId\\\": \\\"81cefad3-d2c9-4f77-a466-99a7f541c7bb\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 30, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/81cefad3-d2c9-4f77-a466-99a7f541c7bb/resourceGroups/aml-quickstarts-154042/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-154042/experiments/Ames-housing-hdr\\\", \\\"SubscriptionId\\\": \\\"81cefad3-d2c9-4f77-a466-99a7f541c7bb\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-154042\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-154042\\\", \\\"ExperimentName\\\": \\\"Ames-housing-hdr\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_xgb.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"cpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"env\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults==1.32.0\\\"]}, \\\"scikit-learn\\\", \\\"xgboost\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"docker\\\": {\\\"useDocker\\\": false, \\\"sharedVolumes\\\": true, \\\"arguments\\\": [], \\\"shmSize\\\": \\\"2g\\\"}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"credentialPassthrough\\\": false, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"8b0edae0-a910-423c-9bd7-2b7b3b6508bf\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"42c57e6c-31b9-4d8c-843b-47f0b5e782c3\\\", \\\"amlClientSessionId\\\": \\\"e4e301eb-3cb7-4026-9713-5d259a796ae3\\\", \\\"subscriptionId\\\": \\\"81cefad3-d2c9-4f77-a466-99a7f541c7bb\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 30, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"false\", \"all_jobs_generated\": \"false\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-08-09T09:16:37.414376\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-08-09T09:16:37.414376\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"19b9078ee79b27289d090eb52f861d887617d833babdbd53f08c6f2791a0f997\\\"\", \"progress_metadata_digest\": \"\\\"19b9078ee79b27289d090eb52f861d887617d833babdbd53f08c6f2791a0f997\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-08-09T09:16:37.414376\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-08-09T09:16:37.414376\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_0\": \"{\\\"--gamma\\\": 5.107686847169128, \\\"--learning_rate\\\": 0.10280301137550896, \\\"--max_depth\\\": 5}\", \"HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_0\": \"{\\\"--gamma\\\": 5.107686847169128, \\\"--learning_rate\\\": 0.10280301137550896, \\\"--max_depth\\\": 5}\", \"_aml_system_HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_1\": \"{\\\"--gamma\\\": 8.196865418162131, \\\"--learning_rate\\\": 0.05911434624909529, \\\"--max_depth\\\": 3}\", \"HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_1\": \"{\\\"--gamma\\\": 8.196865418162131, \\\"--learning_rate\\\": 0.05911434624909529, \\\"--max_depth\\\": 3}\", \"_aml_system_HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_2\": \"{\\\"--gamma\\\": 0.047543031484918785, \\\"--learning_rate\\\": 0.1038000834066989, \\\"--max_depth\\\": 5}\", \"HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_2\": \"{\\\"--gamma\\\": 0.047543031484918785, \\\"--learning_rate\\\": 0.1038000834066989, \\\"--max_depth\\\": 5}\", \"_aml_system_HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_3\": \"{\\\"--gamma\\\": 7.854187767762767, \\\"--learning_rate\\\": 0.04989275587762005, \\\"--max_depth\\\": 7}\", \"HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_3\": \"{\\\"--gamma\\\": 7.854187767762767, \\\"--learning_rate\\\": 0.04989275587762005, \\\"--max_depth\\\": 7}\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg154042.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=%2FhF7tXbpDv1HZ7Cgd1n2qUf1HDiTAnxZFgkj6rOHpiE%3D&st=2021-08-09T09%3A07%3A07Z&se=2021-08-09T17%3A17%3A07Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:00:31\", \"run_number\": \"6\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}, \"hyper_parameters\": {\"--learning_rate\": [\"loguniform\", [-4.6, -1.6]], \"--gamma\": [\"uniform\", [0, 9]], \"--max_depth\": [\"choice\", [[3, 5, 7]]]}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2021-08-09T09:16:37.055359][API][INFO]Experiment created\\r\\n[2021-08-09T09:16:37.599338][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-08-09T09:16:37.815738][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-08-09T09:17:07.3658902Z][SCHEDULER][INFO]Scheduling job, id='HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_1'\\r\\n[2021-08-09T09:17:07.4044532Z][SCHEDULER][INFO]Scheduling job, id='HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_3'\\r\\n[2021-08-09T09:17:07.3646770Z][SCHEDULER][INFO]Scheduling job, id='HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_0'\\r\\n[2021-08-09T09:17:07.3670368Z][SCHEDULER][INFO]Scheduling job, id='HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_2'\\r\\n[2021-08-09T09:17:08.1456379Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790_0'\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.32.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790\n",
            "Web View: https://ml.azure.com/runs/HD_8ae1c9cf-f6e9-4c9e-99f9-cd4ba110d790?wsid=/subscriptions/81cefad3-d2c9-4f77-a466-99a7f541c7bb/resourcegroups/aml-quickstarts-154042/workspaces/quick-starts-ws-154042&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
            "\n",
            "Streaming azureml-logs/hyperdrive.txt\n",
            "=====================================\n",
            "\n",
            "\"<START>[2021-08-09T09:16:37.055359][API][INFO]Experiment created<END>\\n\"\"<START>[2021-08-09T09:16:37.599338][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2021-08-09T09:16:37.815738][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1628500028816
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# Get your best run and save the model from that run.\r\n",
        "best_run, fitted_model = hdr.get_output()\r\n",
        "print(best_run)\r\n",
        "print(fitted_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598546650307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run_metrics = best_run.get_metrics()\r\n",
        "best_run_metrics"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "details = best_run.get_details()\r\n",
        "\r\n",
        "# Save metrics and details for ex-post examination\r\n",
        "with open('best_hdr_metrics.json', 'w') as file:\r\n",
        "    json.dump(best_run_metrics, file)\r\n",
        "with open('best_hdr_details.txt', 'w') as file:\r\n",
        "    file.write(str(details))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\r\n",
        "\r\n",
        "# Check the path to the model\r\n",
        "for i,n in enumerate(best_run.get_file_names()):\r\n",
        "    print(i,n)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598546657829
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\r\n",
        "os.makedirs('./outputs/', exist_ok=True)\r\n",
        "for i in range(32,41):\r\n",
        "    print(best_run.get_file_names()[i])\r\n",
        "    best_run.download_file(best_run.get_file_names()[i], output_file_path='./outputs/')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the best model\r\n",
        "model = Model.register(ws, model_path='outputs/model.pkl', model_name='Ames-Housing-AutoML-Model', tags=best_run_metrics)\r\n",
        "print(model.name, model.id, model.version, sep='\\t')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete() is used to deprovision and delete the AmlCompute target. \n",
        "cpu_cluster.delete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n"
          ]
        }
      ],
      "execution_count": 59,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}